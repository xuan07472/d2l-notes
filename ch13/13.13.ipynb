{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实战 Kaggle ⽐赛：图像分类 (CIFAR-10)\n",
    "''' \n",
    "之前⼏节中，我们⼀直在使⽤深度学习框架的⾼级API直接获取张量格式的图像数据集。但是在实践中，图\n",
    "像数据集通常以图像⽂件的形式出现。在本节中，我们将从原始图像⽂件开始，然后逐步组织、读取并将它\n",
    "们转换为张量格式。\n",
    "我们在 13.1节中对CIFAR-10数据集做了⼀个实验。CIFAR-10是计算机视觉领域中的⼀个重要的数据集。在\n",
    "本节中，我们将运⽤我们在前⼏节中学到的知识来参加CIFAR-10图像分类问题的Kaggle竞赛，⽐赛的⽹址\n",
    "是https://www.kaggle.com/c/cifar-10。\n",
    "图13.13.1显⽰了竞赛⽹站⻚⾯上的信息。为了能提交结果，你需要⾸先注册Kaggle账⼾\n",
    "\n",
    "⾸先，导⼊竞赛所需的包和模块\n",
    "'''\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取并组织数据集\n",
    "''' \n",
    "⽐赛数据集分为训练集和测试集，其中训练集包含50000张、测试集包含300000张图像。在测试集中，10000张\n",
    "图像将被⽤于评估，⽽剩下的290000张图像将不会被进⾏评估，包含它们只是为了防⽌⼿动标记测试集并提\n",
    "交标记结果。两个数据集中的图像都是png格式，⾼度和宽度均为32像素并有三个颜⾊通道（RGB）。这些图\n",
    "⽚共涵盖10个类别：⻜机、汽⻋、⻦类、猫、⿅、狗、⻘蛙、⻢、船和卡⻋。图13.13.1的左上⻆显⽰了数据\n",
    "集中⻜机、汽⻋和⻦类的⼀些图像\n",
    "-------------------------------------------------------------------------------------------\n",
    "下载数据集\n",
    "\n",
    "登录Kaggle后，我们可以点击 图13.13.1中显⽰的CIFAR-10图像分类竞赛⽹⻚上的“Data”选项卡，然后单击\n",
    "“Download All”按钮下载数据集。在../data中解压下载的⽂件并在其中解压缩train.7z和test.7z后，\n",
    "你将在以下路径中找到整个数据集：\n",
    "• ../data/cifar-10/train/[1-50000].png\n",
    "• ../data/cifar-10/test/[1-300000].png\n",
    "• ../data/cifar-10/trainLabels.csv\n",
    "• ../data/cifar-10/sampleSubmission.csv\n",
    "train和test⽂ 件 夹 分 别 包 含 训 练 和 测 试 图 像，trainLabels.csv含 有 训 练 图 像 的 标 签，\n",
    "sample_submission.csv是提交⽂件的范例。\n",
    "为了便于⼊⻔，我们提供包含前1000个训练图像和5个随机测试图像的数据集的⼩规模样本。要使⽤Kaggle竞\n",
    "赛的完整数据集，你需要将以下demo变量设置为False\n",
    "'''\n",
    "#@save\n",
    "d2l.DATA_HUB['cifar10_tiny'] = (d2l.DATA_URL + 'kaggle_cifar10_tiny.zip',\n",
    "                                '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n",
    "# 如果你使⽤完整的Kaggle竞赛的数据集，设置demo为False\n",
    "demo = True\n",
    "if demo:\n",
    "    data_dir = d2l.download_extract('cifar10_tiny')\n",
    "else:\n",
    "    data_dir = '../data/cifar-10/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/kaggle_cifar10_tiny\n",
      "# 训练样本 : 1000\n",
      "# 类别 : 10\n"
     ]
    }
   ],
   "source": [
    "# 整理数据集\n",
    "''' \n",
    "我们需要整理数据集来训练和测试模型。⾸先，我们⽤以下函数读取CSV⽂件中的标签，它返回⼀个字典，该\n",
    "字典将⽂件名中不带扩展名的部分映射到其标签\n",
    "'''\n",
    "#@save\n",
    "def read_csv_labels(fname):\n",
    "    \"\"\"读取fname来给标签字典返回⼀个⽂件名\"\"\"\n",
    "    with open(fname, 'r') as f: # 引入with语句自动调用close()方法\n",
    "        # 跳过⽂件头⾏(列名)\n",
    "        lines = f.readlines()[1:] # 不读取列名\n",
    "        # 因为每行有一个 \\n ，所以要先删除,后根据 \",\"进行分割得到 list\n",
    "    tokens = [l.rstrip().split(',') for l in lines] # 去掉右侧尾部的\\n,并以','切分字符串\n",
    "    return dict(((name, label) for name, label in tokens)) # 逐个迭代token,生成字典对\n",
    "\n",
    "# 将字典对返回给label，做好标签映射\n",
    "labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv')) # 标签\n",
    "print(data_dir) # 文件目录\n",
    "print('# 训练样本 :', len(labels))\n",
    "print('# 类别 :', len(set(labels.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "接下来，我们定义reorg_train_valid函数来将验证集从原始的训练集中拆分出来。此函数中的参\n",
    "数valid_ratio是验证集中的样本数与原始训练集中的样本数之⽐。更具体地说，令n等于样本最少的类\n",
    "别中的图像数量，⽽r是⽐率。验证集将为每个类别拆分出max(⌊nr⌋, 1)张图像。让我们以valid_ratio=0.\n",
    "1为例，由于原始的训练集有50000张图像，因此train_valid_test/train路径中将有45000张图像⽤于\n",
    "训练，⽽剩下5000张图像将作为路径train_valid_test/valid中的验证集。组织数据集后，同类别的图\n",
    "像将被放置在同⼀⽂件夹下\n",
    "--------------------------------------------------------------------------------------\n",
    "#@save 复用代码的一种方法,无特殊含义\n",
    "注释 #@save 是一个特殊标记,会将对应的函数、类或语句保存在d21包中因此，\n",
    "以后无须重新定义就可以直接调用它们\n",
    "例如，d2l.use_svg_display()\n",
    "\n",
    "def use_svg_display():  #@save\n",
    "    \"\"\"使用svg格式在Jupyter中显示绘图\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "--------------------------------------------------------------------------------------\n",
    "os.makedirs(name, mode=0o777, exist_ok=False) # 用来创建多层目录（单层请用os.mkdir)\n",
    "\n",
    "name：你想创建的目录名\n",
    "mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)\n",
    "exist_ok：是否在目录存在时触发异常\n",
    "    如果exist_ok为False（默认值），则在目标目录已存在的情况下触发FileExistsError异常；\n",
    "    如果exist_ok为True，则在目标目录已存在的情况下不会触发FileExistsError异常\n",
    "'''\n",
    "# 将源filename里面的文件拷贝到目标文件夹中\n",
    "#@save\n",
    "def copyfile(filename, target_dir): # 将 filename文件 复制到 target_dir\n",
    "    \"\"\"将⽂件复制到⽬标⽬录\"\"\"\n",
    "    os.makedirs(target_dir, exist_ok=True) # 创建多层目录,若目录存在不会触发异常\n",
    "    shutil.copy(filename, target_dir) # 将 filename 文件复制到 target_dir 目录中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重构原始训练集,将其分为 train_valid,train,valid\n",
    "# \n",
    "''' \n",
    "怎样找出一个序列中出现次数最多的元素呢？\n",
    "\n",
    "collections.Counter 类就是专门为这类问题而设计的， \n",
    "它甚至有一个有用的 most_common() 方法直接给了你答案\n",
    "\n",
    "# 测试 n = collections.Counter(labels.values()).most_common()[-1][1]\n",
    "words = [\n",
    "    'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',\n",
    "    'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the',\n",
    "    'eyes', \"don't\", 'look', 'around', 'the', 'eyes', 'look', 'into',\n",
    "    'my', 'eyes', \"you're\", 'under'\n",
    "]\n",
    "from collections import Counter\n",
    "word_counts = Counter(words)\n",
    "print(word_counts)\n",
    "print(word_counts.most_common())\n",
    "print(word_counts.most_common()[-1][1])\n",
    "'''\n",
    "#@save\n",
    "def reorg_train_valid(data_dir, labels, valid_ratio): # reorg 重组\n",
    "    \"\"\"将验证集从原始的训练集中拆分出来\"\"\"\n",
    "    # 训练数据集中样本最少的类别中的样本数\n",
    "    '''\n",
    "    # labels.values() 以列表的形式返回字典中的所有值\n",
    "    # collections模块 ==> Python标准库，数据结构常用的模块\n",
    "    # Counter() 可接受任意元素构成的序列对象,一个Counter就是一个字典,将元素映射到它出现的次数上\n",
    "    # most_common() 返回一个列表,包含Counter中n个最大数目的元素\n",
    "        如果忽略n或者为None，most_common()将会返回counter中的所有元素，\n",
    "        元素有着相同数目的将会选择出现早的元素\n",
    "    # os.path.join('path','abc','yyy') 拼接文件路径 ->  path\\abc\\yyy\n",
    "    # join 参加,连接,结合\n",
    "    '''\n",
    "    # 返回排序后最后一个类别的值,即样本中最少的类别所具有的样本数\n",
    "    n = collections.Counter(labels.values()).most_common()[-1][1]\n",
    "    # 验证集中每个类别的样本数\n",
    "    # math.floor(x) 方法将 x 向下舍入到最接近的整数\n",
    "    # 即验证集的数量为最少样本类别的valid_ratio倍且最小为1\n",
    "    # 按照比例将部分数据作为验证集\n",
    "    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n",
    "    # print(n_valid_per_label) # -> 8\n",
    "    # 查看label的种类个数\n",
    "    label_count = {}\n",
    "    # 逐个遍历train文件夹里面图片的文件名\n",
    "    # 列出train 路径下所有的文件并遍历给train_file,该数据集是打乱的\n",
    "    for train_file in os.listdir(os.path.join(data_dir, 'train')): # path: data_dir\\train\n",
    "        # 文件名的序号通过labels字典对的映射得到图片对应的实际标签，比如 1 在 csv 中表示 frog\n",
    "\t\t# label 表示图片的实际类别,如 frog 蛙\n",
    "        # 用.将train_file切片，切片后只有两行，第一行为类别标号，第二行为类别名称，\n",
    "        # 我们只取第一行赋值给label\n",
    "        label = labels[train_file.split('.')[0]]\n",
    "        # print(label) 类别名称\n",
    "        # fname=data_dir/train/train_file，train_file有label和名称组成\n",
    "        fname = os.path.join(data_dir, 'train', train_file) # label名,即train_file对应的文件名\n",
    "        # 通过label名来创建文件夹，将对应的图片放到相应的文件夹中\n",
    "        # 即将原训练集 train 中的train复制到 train_valid_test 中的 train_valid\n",
    "        # 将data_dir/train/train_file的文件复制到data_dir/train_valid_test/train_valid/label，\n",
    "        '原始的cifar10数据,未经过划分,用于获得具有超参数的满意模型后对模型进行重新训练'\n",
    "        copyfile(fname, os.path.join(data_dir, 'train_valid_test','train_valid', label))\n",
    "        # 若 label not in label_count 或 label_count[label] < n_valid_per_label\n",
    "        # 即标签不再label_count中或者label标签的样本数量 < n_valid_per_label,就复制到验证集\n",
    "        if label not in label_count or label_count[label] < n_valid_per_label:\n",
    "            # 复制到交叉验证集valid中\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test','valid', label))\n",
    "            # 字典中get返回指定Key的值，如果key不存在则返回后面的参数，即0\n",
    "            # 返回字典label_count中label元素所对应的值，label_count[label]给字典label——count中\n",
    "            # 元素label赋值为label值+1\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "        else:\n",
    "            # 复制到训练集train中\n",
    "            copyfile(fname, os.path.join(data_dir, 'train_valid_test','train', label))\n",
    "    return n_valid_per_label # 将验证集从原始的训练集中拆分出来并返回验证集中每个类别的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理文件夹\n",
    "'下面的reorg_test函数用来在预测期间整理测试集，以方便读取'\n",
    "#@save\n",
    "def reorg_test(data_dir): # 整理测试集\n",
    "    \"\"\"在预测期间整理测试集，以方便读取\"\"\"\n",
    "    # 遍历 test 文件夹，将不同的文件进行拷贝到另一个文件夹中\n",
    "\t# data_dir/test  -> copy -> data_dir/train_valid_test/test/unkown\n",
    "    # 将测试文件夹中的文件放到data_dir/train_valid_test/test/unkown中\n",
    "    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n",
    "        copyfile(os.path.join(data_dir, 'test', test_file),\n",
    "                 os.path.join(data_dir, 'train_valid_test', 'test','unknown')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取reorg_cifa10_data 文件\n",
    "''' \n",
    "最后,我们使⽤⼀个函数来调⽤前⾯定义的 函数 read_csv_labels, reorg_train_valid 和 reorg_test\n",
    "'''\n",
    "def reorg_cifar10_data(data_dir, valid_ratio): # 重构cifar10数据\n",
    "    labels = read_csv_labels(os.path.join(data_dir, 'trainLabels.csv')) # 读取标签\n",
    "    # 重构训练_验证集,返回n_valid_per_label,将训练集分为train_valid,train,valid\n",
    "    reorg_train_valid(data_dir, labels, valid_ratio) \n",
    "    reorg_test(data_dir) # 重构测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "在这⾥，我们只将样本数据集的批量⼤⼩设置为32。在实际训练和测试中，应该使⽤Kaggle竞赛的完整数据\n",
    "集，并将batch_size设置为更⼤的整数，例如128。我们将10％的训练样本作为调整超参数的验证集\n",
    "'''\n",
    "batch_size = 32 if demo else 128\n",
    "valid_ratio = 0.1\n",
    "reorg_cifar10_data(data_dir, valid_ratio) # 对 data_dir 进行重构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像增⼴\n",
    "''' \n",
    "我们使⽤图像增⼴来解决过拟合的问题。例如在训练中，我们可以随机⽔平翻转图像。我们还可以对彩⾊图\n",
    "像的三个RGB通道执⾏标准化。下⾯，我们列出了其中⼀些可以调整的操作\n",
    "'''\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    # 在⾼度和宽度上将图像放⼤到40像素的正⽅形\n",
    "    torchvision.transforms.Resize(40),\n",
    "    # 随机裁剪出⼀个⾼度和宽度均为32像素的正⽅形图像，\n",
    "    # ⽣成⼀个⾯积为原始图像⾯积0.64到1倍的⼩正⽅形，\n",
    "    # 然后将其缩放为⾼度和宽度均为32像素的正⽅形\n",
    "    torchvision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0),ratio=(1.0, 1.0)),\n",
    "    # 随机水平翻转\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    # 图片转成张量\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    # 使用平均值与标准差对图像的三个通道进行归一化\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'在测试期间，我们只对图像执⾏标准化，以消除评估结果中的随机性'\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(), # 图片转换成张量\n",
    "    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],[0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按文件夹读取数据集\n",
    "'''\n",
    "接下来，我们读取由原始图像组成的数据集，每个样本都包括⼀张图⽚和⼀个标签\n",
    "\n",
    "ImageFolder(DatasetFolder) 一个通用数据加载器，默认情况下图像以这种方式排列:\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/[...]/xxz.png\n",
    "\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/[...]/asd932_.png\n",
    "\n",
    "torchvision.datasets.ImageFolder() 返回训练数据与标签\n",
    "'''\n",
    "# image+label -> dataset -> dataloader\n",
    "# 按文件夹形式读取训练集生成 dataset 数据集\n",
    "train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train_valid_test', folder), # 图片路径\n",
    "    transform=transform_train) for folder in ['train', 'train_valid']] # 图像增广\n",
    "''' \n",
    "print(train_ds.classes) # 查看数据集类别\n",
    "print(train_ds.class_to_idx) # 查看类别对应id\n",
    "# print(train_ds.imgs) # 查看图像文件路径\n",
    "'''\n",
    "# 按文件夹形式读取测试集生成 dataset -> ds\n",
    "valid_ds, test_ds = [torchvision.datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train_valid_test', folder),\n",
    "    transform=transform_test) for folder in ['valid', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 torch.utils.data.DataLoader() 构建数据迭代器\n",
    "''' \n",
    "在训练期间，我们需要指定上⾯定义的所有图像增⼴操作。当验证集在超参数调整过程中⽤于模型评估时，\n",
    "不应引⼊图像增⼴的随机性。在最终预测之前，我们根据训练集和验证集组合⽽成的训练模型进⾏训练，以\n",
    "充分利⽤所有标记的数据\n",
    "--------------------------------------------------------------------------------------\n",
    "例:\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(1)    # reproducible\n",
    " \n",
    "BATCH_SIZE = 5      # 批训练的数据个数\n",
    " \n",
    "x = torch.linspace(1, 10, 10)       # x data (torch tensor)\n",
    "y = torch.linspace(10, 1, 10)       # y data (torch tensor)\n",
    " \n",
    "# 先转换成 torch 能识别的 Dataset\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    " \n",
    "# 把 dataset 放入 DataLoader\n",
    "loader = Data.DataLoader(       # 迭代器\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")\n",
    " \n",
    "for epoch in range(3):   # 训练所有!整套!数据 3 次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "        # 假设这里就是你训练的地方...\n",
    " \n",
    "        # 打出来一些数据\n",
    "        print(\\'Epoch: \\', epoch, \\'| Step: \\', step, \\'| batch x: \\',\n",
    "              batch_x.numpy(), \\'| batch y: \\', batch_y.numpy())\n",
    " \n",
    "\"\"\"\n",
    "Epoch:  0 | Step:  0 | batch x:  [ 6.  7.  2.  3.  1.] | batch y:  [  5.   4.   9.   8.  10.]\n",
    "Epoch:  0 | Step:  1 | batch x:  [  9.  10.   4.   8.   5.] | batch y:  [ 2.  1.  7.  3.  6.]\n",
    "Epoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.] | batch y:  [ 8.  7.  9.  2.  1.]\n",
    "Epoch:  1 | Step:  1 | batch x:  [ 1.  7.  8.  5.  6.] | batch y:  [ 10.   4.   3.   6.   5.]\n",
    "Epoch:  2 | Step:  0 | batch x:  [ 3.  9.  2.  6.  7.] | batch y:  [ 8.  2.  9.  5.  4.]\n",
    "Epoch:  2 | Step:  1 | batch x:  [ 10.   4.   8.   1.   5.] | batch y:  [  1.   7.   3.  10.   6.]\n",
    "\"\"\"\n",
    "“”\n",
    "如果改变batch大小每次迭代数据不够batch,则函数就会把剩下的数据输出。\n",
    "“”\n",
    "\n",
    "'''\n",
    "# 训练迭代器,训练_验证迭代器,shuffle=打乱数据提高鲁棒，\n",
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, train_valid_ds)] # 对数据进行batch划分,生成迭代器\n",
    "# 测试与验证迭代器无需打乱\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,drop_last=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "'我们定义了 7.6节中描述的Resnet-18模型'\n",
    "def get_net():\n",
    "    num_classes = 10\n",
    "    net = d2l.resnet18(num_classes, 3) # 调用 Resnet-18 模型\n",
    "    return net\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "'我们将根据模型在验证集上的表现来选择模型并调整超参数。下⾯我们定义了模型训练函数train'\n",
    "def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay):\n",
    "\t\"\"\"\n",
    "\tfunction : 定义训练函数\n",
    "\t:param net: 神经网络\n",
    "\t:param train_iter: 训练迭代器\n",
    "\t:param valid_iter: 验证迭代器\n",
    "\t:param num_epochs: 迭代的次数\n",
    "\t:param lr: 学习率\n",
    "\t:param wd: 权重衰减\n",
    "\t:param devices: GPU\n",
    "\t:param lr_period: 每step_size个周期按 lr_decay 衰减每个参数组的学习率。\n",
    "\t:param lr_decay:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\t# 定义优化器 SGD 随机梯度下降\n",
    "\ttrainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9,weight_decay=wd)\n",
    "\t# 设置优化器trainer中学习率改变的方式，\n",
    "\tscheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n",
    "\t# 设置批量大小和计时器\n",
    "\tnum_batches, timer = len(train_iter), d2l.Timer()\n",
    "\t# 设置画布上的显示值\n",
    "\tlegend = ['train loss', 'train acc']\n",
    "\t# 如果有验证集，就增加到显示画布上\n",
    "\tif valid_iter is not None:\n",
    "\t\tlegend.append('valid acc')\n",
    "\t# 画动图,x轴是迭代次数,\n",
    "\tanimator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "\t\t\t\t\t\t\tlegend=legend)\n",
    "\t# 实现模型上的数据并行\n",
    "\t''' \n",
    "\tCLASS torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)\n",
    " \t数据并行,实现多个GPU训练,其中input数据平行,但output loss会在output_device中相加计算\n",
    "\tmodel.to(devices[0])  最开始读取数据时的tensor变量copy一份到device所指定的GPU上去\n",
    " \n",
    "\tmodel = model.cuda() \n",
    "\tdevice_ids = [0, 1] \t# id为0和1的两块显卡\n",
    "\tmodel = torch.nn.DataParallel(model, device_ids=device_ids)\n",
    " \n",
    "\t或:\n",
    " \n",
    "\tdevice_ids = [0, 1]\n",
    "\tmodel = torch.nn.DataParallel(model, device_ids=device_ids).cuda()\n",
    "\t'''\n",
    "\tnet = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\t# 启动神经网络的训练模式\n",
    "\t\tnet.train()\n",
    "\t\t# 定义累加器\n",
    "\t\tmetric = d2l.Accumulator(3)\n",
    "\t\t# 从训练迭代器中成对的拿到 (features,labels)\n",
    "\t\tfor i, (features, labels) in enumerate(train_iter):\n",
    "\t\t\t# 计时开始\n",
    "\t\t\ttimer.start()\n",
    "\t\t\t# 根据训练集中的features,labels得到损失l和精度acc\n",
    "\t\t\t# 在GPU上进行小批量训练数据\n",
    "\t\t\tl, acc = d2l.train_batch_ch13(net, features, labels,\n",
    "\t\t\t\t\t\t\t\t\t\t  loss, trainer, devices)\n",
    "\t\t\t# 累加器增加数据\n",
    "\t\t\tmetric.add(l, acc, labels.shape[0])\n",
    "\t\t\t# 计时结束\n",
    "\t\t\ttimer.stop()\n",
    "\t\t\tif (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "\t\t\t\tanimator.add(epoch + (i + 1) / num_batches,\n",
    "\t\t\t\t\t\t\t (metric[0] / metric[2], metric[1] / metric[2], None))\n",
    "\t\tif valid_iter is not None: # 若有验证集\n",
    "\t\t\tvalid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)\n",
    "\t\t\tanimator.add(epoch + 1, (None, None, valid_acc))\n",
    "\t\t# 调度器更新\n",
    "\t\tscheduler.step()\n",
    "  \n",
    "\tmeasures = (f'train loss{metric[0] / metric[2]:.3f},'\n",
    "\t\t\t\tf'train acc {metric[1] / metric[2]:.3f}')\n",
    "\tif valid_iter is not None:\n",
    "\t\tmeasures += f',valid acc{valid_acc:3f}'\n",
    "\tprint(measures + f'\\n{metric[2] * num_epochs / timer.sum():.1f}'\n",
    "\t\t\t\t\t f'examples/sec on {str(devices)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss0.570,train acc 0.807,valid acc0.515625\n",
      "1176.2examples/sec on [device(type='cuda', index=0)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"180.65625pt\" viewBox=\"0 0 238.965625 180.65625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-02-12T11:00:51.971682</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 238.965625 180.65625 \nL 238.965625 0 \nL 0 0 \nL 0 180.65625 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 71.218914 143.1 \nL 71.218914 7.2 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"mf13aea34b8\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mf13aea34b8\" x=\"71.218914\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 5 -->\n      <g transform=\"translate(68.037664 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 122.613651 143.1 \nL 122.613651 7.2 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mf13aea34b8\" x=\"122.613651\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(116.251151 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 174.008388 143.1 \nL 174.008388 7.2 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mf13aea34b8\" x=\"174.008388\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 15 -->\n      <g transform=\"translate(167.645888 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mf13aea34b8\" x=\"225.403125\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 20 -->\n      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path d=\"M 30.103125 141.825096 \nL 225.403125 141.825096 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m8c1f80e5bc\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8c1f80e5bc\" x=\"30.103125\" y=\"141.825096\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 145.624314)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path d=\"M 30.103125 113.811562 \nL 225.403125 113.811562 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m8c1f80e5bc\" x=\"30.103125\" y=\"113.811562\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 117.610781)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path d=\"M 30.103125 85.798029 \nL 225.403125 85.798029 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m8c1f80e5bc\" x=\"30.103125\" y=\"85.798029\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 89.597247)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_15\">\n      <path d=\"M 30.103125 57.784495 \nL 225.403125 57.784495 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m8c1f80e5bc\" x=\"30.103125\" y=\"57.784495\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 61.583714)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_17\">\n      <path d=\"M 30.103125 29.770962 \nL 225.403125 29.770962 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m8c1f80e5bc\" x=\"30.103125\" y=\"29.770962\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 33.57018)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 21.659704 13.377273 \nL 23.49523 13.862728 \nL 25.330757 14.664366 \nL 27.166283 17.920308 \nL 29.001809 19.128732 \nL 30.103125 19.394488 \nL 31.938651 22.100158 \nL 33.774178 20.701405 \nL 35.609704 21.356027 \nL 37.44523 22.393852 \nL 39.280757 25.38778 \nL 40.382072 26.783755 \nL 42.217599 41.662414 \nL 44.053125 43.206213 \nL 45.888651 44.770298 \nL 47.724178 42.500427 \nL 49.559704 43.556673 \nL 50.66102 43.029759 \nL 52.496546 47.263024 \nL 54.332072 43.764746 \nL 56.167599 47.439175 \nL 58.003125 46.27084 \nL 59.838651 46.543233 \nL 60.939967 46.403073 \nL 62.775493 50.104402 \nL 64.61102 52.008546 \nL 66.446546 50.255105 \nL 68.282072 53.298543 \nL 70.117599 51.630708 \nL 71.218914 51.180673 \nL 73.054441 59.85802 \nL 74.889967 56.015291 \nL 76.725493 58.438149 \nL 78.56102 55.586565 \nL 80.396546 54.931287 \nL 81.497862 54.114358 \nL 83.333388 56.398178 \nL 85.168914 53.699629 \nL 87.004441 54.684685 \nL 88.839967 55.336228 \nL 90.675493 55.995425 \nL 91.776809 56.621781 \nL 93.612336 60.047539 \nL 95.447862 62.675054 \nL 97.283388 64.070153 \nL 99.118914 64.466973 \nL 100.954441 63.371879 \nL 102.055757 63.722426 \nL 103.891283 78.562397 \nL 105.726809 72.763857 \nL 107.562336 72.038166 \nL 109.397862 73.481058 \nL 111.233388 72.389844 \nL 112.334704 72.469404 \nL 114.17023 83.697812 \nL 116.005757 84.690135 \nL 117.841283 81.092377 \nL 119.676809 77.709225 \nL 121.512336 77.384282 \nL 122.613651 77.734175 \nL 124.449178 84.864444 \nL 126.284704 80.645303 \nL 128.12023 78.896176 \nL 129.955757 77.820372 \nL 131.791283 77.025755 \nL 132.892599 77.083222 \nL 134.728125 82.74987 \nL 136.563651 78.514495 \nL 138.399178 78.44601 \nL 140.234704 79.305614 \nL 142.07023 78.235221 \nL 143.171546 76.951513 \nL 145.007072 90.235439 \nL 146.842599 89.183799 \nL 148.678125 86.134423 \nL 150.513651 88.827829 \nL 152.349178 87.684379 \nL 153.450493 87.733209 \nL 155.28602 86.944407 \nL 157.121546 82.247732 \nL 158.957072 84.432729 \nL 160.792599 84.382715 \nL 162.628125 84.430559 \nL 163.729441 84.347956 \nL 165.564967 103.887103 \nL 167.400493 97.149993 \nL 169.23602 96.393035 \nL 171.071546 95.327199 \nL 172.907072 94.523184 \nL 174.008388 93.61281 \nL 175.843914 98.860047 \nL 177.679441 98.718787 \nL 179.514967 98.357081 \nL 181.350493 97.400006 \nL 183.18602 97.704737 \nL 184.287336 96.874567 \nL 186.122862 100.656233 \nL 187.958388 102.658805 \nL 189.793914 102.304709 \nL 191.629441 100.222421 \nL 193.464967 101.165632 \nL 194.566283 101.695873 \nL 196.401809 98.754948 \nL 198.237336 102.076794 \nL 200.072862 103.942991 \nL 201.908388 101.593586 \nL 203.743914 102.655844 \nL 204.84523 101.818015 \nL 206.680757 109.486457 \nL 208.516283 110.742613 \nL 210.351809 110.632216 \nL 212.187336 110.867138 \nL 214.022862 108.468129 \nL 215.124178 108.571345 \nL 216.959704 107.377689 \nL 218.79523 111.07711 \nL 220.630757 111.692059 \nL 222.466283 110.678994 \nL 224.301809 109.9007 \nL 225.403125 109.887132 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 21.659704 136.922727 \nL 23.49523 133.070866 \nL 25.330757 131.320021 \nL 27.166283 130.181971 \nL 29.001809 129.008904 \nL 30.103125 128.881342 \nL 31.938651 127.46816 \nL 33.774178 128.168498 \nL 35.609704 128.401944 \nL 37.44523 128.080956 \nL 39.280757 127.608227 \nL 40.382072 126.942906 \nL 42.217599 123.616299 \nL 44.053125 121.340199 \nL 45.888651 119.997884 \nL 47.724178 121.252657 \nL 49.559704 120.955013 \nL 50.66102 121.315187 \nL 52.496546 119.0641 \nL 54.332072 120.814945 \nL 56.167599 119.764438 \nL 58.003125 120.377234 \nL 59.838651 120.604844 \nL 60.939967 120.752415 \nL 62.775493 120.814945 \nL 64.61102 119.764438 \nL 66.446546 118.947377 \nL 68.282072 118.101134 \nL 70.117599 118.924032 \nL 71.218914 119.001569 \nL 73.054441 116.262746 \nL 74.889967 117.313254 \nL 76.725493 116.612915 \nL 78.56102 117.663423 \nL 80.396546 118.15366 \nL 81.497862 118.376267 \nL 83.333388 115.912577 \nL 85.168914 116.788 \nL 87.004441 116.963085 \nL 88.839967 117.663423 \nL 90.675493 117.383288 \nL 91.776809 117.000603 \nL 93.612336 115.562408 \nL 95.447862 115.037154 \nL 97.283388 114.5119 \nL 99.118914 115.037154 \nL 100.954441 114.581934 \nL 102.055757 114.624455 \nL 103.891283 105.407502 \nL 105.726809 109.959701 \nL 107.562336 110.776763 \nL 109.397862 110.922666 \nL 111.233388 111.080243 \nL 112.334704 110.997703 \nL 114.17023 107.158348 \nL 116.005757 107.508517 \nL 117.841283 109.376086 \nL 119.676809 110.66004 \nL 121.512336 110.519972 \nL 122.613651 110.24734 \nL 124.449178 107.158348 \nL 126.284704 108.559025 \nL 128.12023 109.259363 \nL 129.955757 109.872159 \nL 131.791283 110.239837 \nL 132.892599 110.12228 \nL 134.728125 108.208855 \nL 136.563651 108.559025 \nL 138.399178 108.792471 \nL 140.234704 108.121313 \nL 142.07023 108.979228 \nL 143.171546 109.559508 \nL 145.007072 101.555641 \nL 146.842599 103.656656 \nL 148.678125 104.94061 \nL 150.513651 103.919283 \nL 152.349178 104.847231 \nL 153.450493 104.932272 \nL 155.28602 106.808179 \nL 157.121546 108.559025 \nL 158.957072 107.275071 \nL 160.792599 107.24589 \nL 162.628125 107.368449 \nL 163.729441 107.621071 \nL 165.564967 97.70378 \nL 167.400493 101.205472 \nL 169.23602 101.789087 \nL 171.071546 102.168437 \nL 172.907072 102.676183 \nL 174.008388 102.931306 \nL 175.843914 100.505134 \nL 177.679441 100.680218 \nL 179.514967 100.388411 \nL 181.350493 101.030387 \nL 183.18602 100.925337 \nL 184.287336 101.430581 \nL 186.122862 100.855303 \nL 187.958388 99.97988 \nL 189.793914 100.038241 \nL 191.629441 100.855303 \nL 193.464967 100.855303 \nL 194.566283 100.617688 \nL 196.401809 100.855303 \nL 198.237336 99.97988 \nL 200.072862 99.104457 \nL 201.908388 100.330049 \nL 203.743914 99.804795 \nL 204.84523 100.054916 \nL 206.680757 96.653273 \nL 208.516283 96.828357 \nL 210.351809 96.53655 \nL 212.187336 96.653273 \nL 214.022862 97.353611 \nL 215.124178 97.303587 \nL 216.959704 97.353611 \nL 218.79523 96.828357 \nL 220.630757 95.952934 \nL 222.466283 96.390646 \nL 224.301809 96.443171 \nL 225.403125 96.615755 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path d=\"M 30.103125 128.693752 \nL 40.382072 123.441214 \nL 50.66102 128.693752 \nL 60.939967 125.19206 \nL 71.218914 126.067483 \nL 81.497862 125.19206 \nL 91.776809 119.939523 \nL 102.055757 119.939523 \nL 112.334704 115.562408 \nL 122.613651 119.0641 \nL 132.892599 117.313254 \nL 143.171546 114.686985 \nL 153.450493 120.814945 \nL 163.729441 118.188677 \nL 174.008388 118.188677 \nL 184.287336 113.811562 \nL 194.566283 115.562408 \nL 204.84523 118.188677 \nL 215.124178 119.0641 \nL 225.403125 112.936139 \n\" clip-path=\"url(#p5162ab8265)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 143.1 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 59.234375 \nL 218.403125 59.234375 \nQ 220.403125 59.234375 220.403125 57.234375 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 140.634375 12.2 \nQ 138.634375 12.2 138.634375 14.2 \nL 138.634375 57.234375 \nQ 138.634375 59.234375 140.634375 59.234375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 142.634375 20.298438 \nL 152.634375 20.298438 \nL 162.634375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train loss -->\n     <g transform=\"translate(170.634375 23.798438)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_23\">\n     <path d=\"M 142.634375 34.976562 \nL 152.634375 34.976562 \nL 162.634375 34.976562 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n    <g id=\"line2d_24\">\n     <path d=\"M 142.634375 49.654688 \nL 152.634375 49.654688 \nL 162.634375 49.654688 \n\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- valid acc -->\n     <g transform=\"translate(170.634375 53.154688)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"176.025391\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.501953\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"271.289062\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"332.568359\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"387.548828\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5162ab8265\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"135.9\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  训练和验证模型\n",
    "''' \n",
    "现在，我们可以训练和验证模型了，⽽以下所有超参数都可以调整。例如，我们可以增加周期的数量。\n",
    "当lr_period和lr_decay分别设置为4和0.9时，优化算法的学习速率将在每4个周期乘以0.9。为便于演⽰，\n",
    "我们在这⾥只训练20个周期\n",
    "'''\n",
    "devices, num_epochs, lr, wd = d2l.try_all_gpus(), 20, 2e-4, 5e-4\n",
    "lr_period, lr_decay, net = 4, 0.9, get_net()\n",
    "train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss0.616,train acc 0.773\n",
      "1427.9examples/sec on [device(type='cuda', index=0)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"180.65625pt\" viewBox=\"0 0 238.965625 180.65625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-02-12T11:01:21.562738</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 180.65625 \nL 238.965625 180.65625 \nL 238.965625 0 \nL 0 0 \nL 0 180.65625 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \nL 225.403125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 71.218914 143.1 \nL 71.218914 7.2 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path id=\"m8a767cf2ec\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m8a767cf2ec\" x=\"71.218914\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 5 -->\n      <g transform=\"translate(68.037664 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 122.613651 143.1 \nL 122.613651 7.2 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m8a767cf2ec\" x=\"122.613651\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(116.251151 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 174.008388 143.1 \nL 174.008388 7.2 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m8a767cf2ec\" x=\"174.008388\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 15 -->\n      <g transform=\"translate(167.645888 157.698438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m8a767cf2ec\" x=\"225.403125\" y=\"143.1\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 20 -->\n      <g transform=\"translate(219.040625 157.698438)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_5\">\n     <!-- epoch -->\n     <g transform=\"translate(112.525 171.376563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <path d=\"M 30.103125 142.928216 \nL 225.403125 142.928216 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m2bb0be91cd\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2bb0be91cd\" x=\"30.103125\" y=\"142.928216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 146.727435)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path d=\"M 30.103125 115.474552 \nL 225.403125 115.474552 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m2bb0be91cd\" x=\"30.103125\" y=\"115.474552\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 119.27377)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_13\">\n      <path d=\"M 30.103125 88.020887 \nL 225.403125 88.020887 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m2bb0be91cd\" x=\"30.103125\" y=\"88.020887\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 91.820105)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_15\">\n      <path d=\"M 30.103125 60.567222 \nL 225.403125 60.567222 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m2bb0be91cd\" x=\"30.103125\" y=\"60.567222\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 64.36644)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_17\">\n      <path d=\"M 30.103125 33.113557 \nL 225.403125 33.113557 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m2bb0be91cd\" x=\"30.103125\" y=\"33.113557\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 36.912775)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 21.813651 13.377273 \nL 23.803125 13.711996 \nL 25.792599 17.493009 \nL 27.782072 19.141938 \nL 29.771546 19.028661 \nL 30.103125 19.30751 \nL 32.092599 23.86074 \nL 34.082072 30.56564 \nL 36.071546 31.424848 \nL 38.06102 32.878014 \nL 40.050493 32.87135 \nL 40.382072 32.604668 \nL 42.371546 46.74736 \nL 44.36102 41.279143 \nL 46.350493 42.553253 \nL 48.339967 42.47409 \nL 50.329441 43.576095 \nL 50.66102 43.655903 \nL 52.650493 56.358662 \nL 54.639967 50.101698 \nL 56.629441 48.092826 \nL 58.618914 47.945317 \nL 60.608388 49.553789 \nL 60.939967 49.717439 \nL 62.929441 60.211535 \nL 64.918914 59.859039 \nL 66.908388 57.217523 \nL 68.897862 55.718428 \nL 70.887336 55.832635 \nL 71.218914 55.569641 \nL 73.208388 58.553707 \nL 75.197862 60.536332 \nL 77.187336 57.588879 \nL 79.176809 55.364801 \nL 81.166283 54.84488 \nL 81.497862 54.295606 \nL 83.487336 61.103601 \nL 85.476809 61.06298 \nL 87.466283 62.344238 \nL 89.455757 58.926259 \nL 91.44523 58.634414 \nL 91.776809 58.1033 \nL 93.766283 61.696855 \nL 95.755757 62.025116 \nL 97.74523 65.327162 \nL 99.734704 64.416287 \nL 101.724178 66.383752 \nL 102.055757 66.556282 \nL 104.04523 74.542334 \nL 106.034704 73.97637 \nL 108.024178 75.427854 \nL 110.013651 74.85297 \nL 112.003125 72.236139 \nL 112.334704 72.039448 \nL 114.324178 82.001679 \nL 116.313651 80.532052 \nL 118.303125 82.129399 \nL 120.292599 80.36869 \nL 122.282072 78.675347 \nL 122.613651 78.060336 \nL 124.603125 83.258555 \nL 126.592599 78.257638 \nL 128.582072 79.730673 \nL 130.571546 76.587389 \nL 132.56102 77.043582 \nL 132.892599 77.193998 \nL 134.882072 84.904868 \nL 136.871546 83.894271 \nL 138.86102 85.111933 \nL 140.850493 85.445534 \nL 142.839967 84.120645 \nL 143.171546 83.601513 \nL 145.16102 75.419573 \nL 147.150493 83.732702 \nL 149.139967 85.461844 \nL 151.129441 86.732538 \nL 153.118914 85.202707 \nL 153.450493 84.971124 \nL 155.439967 91.63215 \nL 157.429441 90.796134 \nL 159.418914 90.522772 \nL 161.408388 89.213612 \nL 163.397862 87.670512 \nL 163.729441 88.072327 \nL 165.718914 96.7809 \nL 167.708388 94.510804 \nL 169.697862 94.002854 \nL 171.687336 94.033354 \nL 173.676809 92.485386 \nL 174.008388 92.624572 \nL 175.997862 98.774966 \nL 177.987336 101.75312 \nL 179.976809 101.291969 \nL 181.966283 99.031759 \nL 183.955757 99.641695 \nL 184.287336 99.283719 \nL 186.276809 97.405701 \nL 188.266283 100.151716 \nL 190.255757 99.21041 \nL 192.24523 102.048531 \nL 194.234704 102.825538 \nL 194.566283 102.43346 \nL 196.555757 106.907888 \nL 198.54523 104.964341 \nL 200.534704 104.279315 \nL 202.524178 104.23965 \nL 204.513651 102.936572 \nL 204.84523 102.908598 \nL 206.834704 108.15224 \nL 208.824178 107.084662 \nL 210.813651 107.553007 \nL 212.803125 105.799827 \nL 214.792599 104.987643 \nL 215.124178 104.760778 \nL 217.113651 110.438341 \nL 219.103125 110.88026 \nL 221.092599 109.574217 \nL 223.082072 108.961553 \nL 225.071546 109.558852 \nL 225.403125 109.112336 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path d=\"M 21.813651 136.922727 \nL 23.803125 136.493764 \nL 25.792599 134.825572 \nL 27.782072 133.491019 \nL 29.771546 132.690287 \nL 30.103125 132.577742 \nL 32.092599 128.915408 \nL 34.082072 125.912664 \nL 36.071546 126.722928 \nL 38.06102 126.842085 \nL 40.050493 127.542725 \nL 40.382072 127.762281 \nL 42.371546 123.195895 \nL 44.36102 124.625773 \nL 46.350493 123.958497 \nL 48.339967 124.053822 \nL 50.329441 123.539066 \nL 50.66102 123.44497 \nL 52.650493 120.050162 \nL 54.639967 121.194065 \nL 56.629441 121.575366 \nL 58.618914 121.408547 \nL 60.608388 121.194065 \nL 60.939967 121.175615 \nL 62.929441 119.192235 \nL 64.918914 119.478211 \nL 66.908388 119.573536 \nL 68.897862 120.407632 \nL 70.887336 120.278943 \nL 71.218914 120.511413 \nL 73.208388 118.90626 \nL 75.197862 120.19315 \nL 77.187336 119.954837 \nL 79.176809 120.264644 \nL 81.166283 120.736504 \nL 81.497862 120.843514 \nL 83.487336 118.048333 \nL 85.476809 117.476381 \nL 87.466283 117.857682 \nL 89.455757 119.263729 \nL 91.44523 119.24943 \nL 91.776809 119.293711 \nL 93.766283 116.90443 \nL 95.755757 117.333393 \nL 97.74523 116.046503 \nL 99.734704 116.54696 \nL 101.724178 115.817722 \nL 102.055757 115.585252 \nL 104.04523 115.760527 \nL 106.034704 114.187661 \nL 108.024178 112.805445 \nL 110.013651 112.614795 \nL 112.003125 113.758697 \nL 112.334704 113.703347 \nL 114.324178 108.897111 \nL 116.313651 110.326989 \nL 118.303125 110.231664 \nL 120.292599 111.041929 \nL 122.282072 111.528087 \nL 122.613651 111.932143 \nL 124.603125 107.753208 \nL 126.592599 110.755953 \nL 128.582072 110.51764 \nL 130.571546 111.828362 \nL 132.56102 111.699673 \nL 132.892599 111.821443 \nL 134.882072 107.753208 \nL 136.871546 108.611135 \nL 138.86102 108.420485 \nL 140.850493 108.754123 \nL 142.839967 109.469062 \nL 143.171546 109.552088 \nL 145.16102 110.326989 \nL 147.150493 109.61205 \nL 149.139967 108.801786 \nL 151.129441 109.040099 \nL 153.118914 109.469062 \nL 153.450493 109.662788 \nL 155.439967 108.039184 \nL 157.429441 107.038269 \nL 159.418914 106.990606 \nL 161.408388 107.252751 \nL 163.397862 107.810403 \nL 163.729441 107.780883 \nL 165.718914 105.179427 \nL 167.708388 104.3215 \nL 169.697862 103.940199 \nL 171.687336 104.392994 \nL 173.676809 105.065037 \nL 174.008388 105.068727 \nL 175.997862 102.31967 \nL 177.987336 102.605646 \nL 179.976809 102.414996 \nL 181.966283 103.535067 \nL 183.955757 103.635158 \nL 184.287336 103.851024 \nL 186.276809 103.463573 \nL 188.266283 102.033695 \nL 190.255757 102.796297 \nL 192.24523 101.533237 \nL 194.234704 101.232963 \nL 194.566283 101.526319 \nL 196.555757 100.031865 \nL 198.54523 101.747719 \nL 200.534704 101.938369 \nL 202.524178 102.033695 \nL 204.513651 102.548451 \nL 204.84523 102.522621 \nL 206.834704 101.461743 \nL 208.824178 101.604731 \nL 210.813651 100.985117 \nL 212.803125 101.819213 \nL 214.792599 101.633329 \nL 215.124178 101.692369 \nL 217.113651 99.745889 \nL 219.103125 99.316926 \nL 221.092599 99.745889 \nL 223.082072 100.389335 \nL 225.071546 100.20345 \nL 225.403125 100.474666 \n\" clip-path=\"url(#p5460c54181)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"line2d_21\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 143.1 \nL 30.103125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 225.403125 143.1 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 143.1 \nL 225.403125 143.1 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 225.403125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 140.634375 44.55625 \nL 218.403125 44.55625 \nQ 220.403125 44.55625 220.403125 42.55625 \nL 220.403125 14.2 \nQ 220.403125 12.2 218.403125 12.2 \nL 140.634375 12.2 \nQ 138.634375 12.2 138.634375 14.2 \nL 138.634375 42.55625 \nQ 138.634375 44.55625 140.634375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_22\">\n     <path d=\"M 142.634375 20.298437 \nL 152.634375 20.298437 \nL 162.634375 20.298437 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_11\">\n     <!-- train loss -->\n     <g transform=\"translate(170.634375 23.798437)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n     </g>\n    </g>\n    <g id=\"line2d_23\">\n     <path d=\"M 142.634375 34.976562 \nL 152.634375 34.976562 \nL 162.634375 34.976562 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_12\">\n     <!-- train acc -->\n     <g transform=\"translate(170.634375 38.476562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5460c54181\">\n   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"135.9\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' \n",
    "在获得具有超参数的满意的模型后，我们使⽤所有标记的数据（包括验证集）\n",
    "即 train_valid_iter 来重新训练模型并对测试集进⾏分类\n",
    "'''\n",
    "net, preds = get_net(), []\n",
    "train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period,lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 Kaggle 上对测试集进⾏分类并提交结果\n",
    "for X, _ in test_iter: # 逐个从测试迭代器中拿到数据X\n",
    "    y_hat = net(X.to(devices[0])) # 将 X 放到GPU上后进行预测\n",
    "    # extend方法只能接收list，且把这个list中的每个元素添加到原list中\n",
    "    # append方法可以接收任意数据类型的参数，并且简单地追加到list尾部\n",
    "    ''' \n",
    "    A = ['q', 'w', 'e', 'r']\n",
    "    A.extend(['t', 'y'])\n",
    "    print(A)\n",
    "    # ['q', 'w', 'e', 'r', 't', 'y']\n",
    "    print(len(A)) # 6\n",
    "    \n",
    "    B = ['q', 'w', 'e', 'r']\n",
    "    B.append(['t', 'y'])\n",
    "    print(B)\n",
    "    # ['q', 'w', 'e', 'r', ['t', 'y']]\n",
    "    print(len(B)) # 5\n",
    "    '''\n",
    "    preds.extend(y_hat.argmax(dim=1).type(torch.int32).cpu().numpy()) # 求出概率最大的标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sorted_ids = list(range(1, len(test_ds) + 1)) # 生成一个大小为测试集的列表\n",
    "print(sorted_ids) # -> [1, 2, 3, 4, 5]\n",
    "type(sorted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作\n",
    "\n",
    "lambda是一个隐函数，是固定写法，不要写成别的单词；\n",
    "x表示列表中的一个元素，x只是临时起的一个名字，你可以使用任意的名字；\n",
    "'''\n",
    "sorted_ids.sort(key=lambda x: str(x)) # 对列表内的元素进行排序\n",
    "print(sorted_ids) # -> [1, 2, 3, 4, 5]\n",
    "type(sorted_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({'id': sorted_ids, 'label': preds}) # DataFrame 构建表格\n",
    "# 将df中表示 label 的数字序号转换为 label 的类别名称\n",
    "df['label'] = df['label'].apply(lambda x: train_valid_ds.classes[x])\n",
    "print(train_valid_ds.classes[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False) # 转换成csv进行保存，方便提交预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n向Kaggle提交结果的⽅法与 4.10节中的⽅法类似，上⾯的代码将⽣成⼀个 submission.csv⽂件，其格式\\n符合Kaggle竞赛的要求\\n--------------------------------------------------------------------------------------------\\n⼩结\\n• 将包含原始图像⽂件的数据集组织为所需格式后，我们可以读取它们\\n• 我们可以在图像分类竞赛中使⽤卷积神经⽹络和图像增⼴\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "向Kaggle提交结果的⽅法与 4.10节中的⽅法类似，上⾯的代码将⽣成⼀个 submission.csv⽂件，其格式\n",
    "符合Kaggle竞赛的要求\n",
    "--------------------------------------------------------------------------------------------\n",
    "⼩结\n",
    "• 将包含原始图像⽂件的数据集组织为所需格式后，我们可以读取它们\n",
    "• 我们可以在图像分类竞赛中使⽤卷积神经⽹络和图像增⼴\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbb412de504602cf3af13b2245b631c81b4c2841b1a325e0f1c2b48c8f82890b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
